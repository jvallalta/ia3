{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "02-Pytorch-Regresion_Lineal.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8RQ6rbisrLy0",
        "CP0-TRTLrLy2",
        "SwGf-LYnrLy8",
        "0KmMqA8IrLzA",
        "EI0qiKAFrLzD",
        "3K1ZnLVvrLzE",
        "vBXlTCArrLzH",
        "1KWQ_1_rrLzL",
        "4nSexto8rLzR",
        "n2QOf-HEltUP"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvallalta/ia3/blob/main/02_Pytorch_Regresion_Lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPSdPkCrLyk"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n",
        "\n",
        "#**Máster en Inteligencia Artificial Avanzada y Aplicada:  IA^3**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WOIeW_unJDd"
      },
      "source": [
        "#<center>**Regresion Lineal y descenso de gradiente con PyTorch**</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uriFNBrirLyw"
      },
      "source": [
        "Este notebook cubre los siguientes aspectos:\n",
        "\n",
        "- Regresion lineal y ajuste empleando descenso de gradiente\n",
        "- Implementación de modelos de este tipo empleando tensores Pytorch\n",
        "- Entrenamiento del modelo de regresion lineal usando el descenso de gradiente\n",
        "- Implementación de ambos empleando las clases y métodos específicamente preparados en Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RQ6rbisrLy0"
      },
      "source": [
        "## Regresión lineal\n",
        "\n",
        "En este notebook vamos a repasar una de las técnicas básicas y fundacionales del aprendizaje máquina y de las redes neuronales: la *regresión lineal*. \n",
        "Vamos a crear un modelo que prediga la cosecha a recoger de manzanas y naranjas (*target variables*) a partir de las observaciones de temperatura, lluvia y humedad (*input variables o features*) en una región. Estos son los datos de entrenamiento:\n",
        "\n",
        "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
        "\n",
        "En un modelo de regresión lineal cada variable dependiente o *target* es estimada como la suma ponderada de las variables de entrada, más un valor constante de ajuste, conocido como *bias* :\n",
        "\n",
        "```\n",
        "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visualmente esto significa que la cosecha de manzanas es una función lineal *o planar*  de la temperatura, la lluvía y la humedad:\n",
        "\n",
        "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu9QdXVjrLy1"
      },
      "source": [
        "La parte de aprendizaje en una función de regresión lineal consiste en obtener un conjunto de pesos o coeficientes `w11, w12,... w23, b1 y b2` empleando los datos de entrenamiento, con la finalidad de poder hacer predicciones para nuevos datos. \n",
        "Los pesos *aprendidos* serán empleados para predecir los valores de cosecha de manzanas y naranjas en una región empleando los datos de temperatura, lluvia y humedad de esa región. . \n",
        "\n",
        "El entrenamiento que vamos a realizar consiste en ir ajustando los pesos ligeramente muchas veces para ir obteniendo mejores predicciones a partir de los valores resultantes conocidos y empleando una técnica de optimización ampliamente usada y conocida llamada *descenso de gradiente*.\n",
        "\n",
        "Empezamos por importar Numpy y Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOgTUnE1rLy1"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP0-TRTLrLy2"
      },
      "source": [
        "## Datos de entrenamiento\n",
        "\n",
        "Vamos a emplear para representar los datos de entrenamiento dos matrices: `inputs` y `targets`, cada fila será una observación y cada coluumna una variable\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZL_bN93rLy2"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPWDvZwrLy3"
      },
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_7f7IlrLy4"
      },
      "source": [
        "Separamos las entradas y los targets porque hemos de trabajar separadamente con cada una de ellas. Por otro lado, se han creado como arrays Numpy porque es la forma habitual en que los vamos a encontrar: importación de los datos CSV como arrays, prepararlos y finalmente convertirlos a tensores de Pytorch.\n",
        "\n",
        "Los convertimos a tensores PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi62YPcXrLy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532e086d-e043-42b5-dc24-6620ee049d01"
      },
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwGf-LYnrLy8"
      },
      "source": [
        "## Modelo de regresion lineal desde cero\n",
        "\n",
        "Los pesos y ajustes (`w11, w12,... w23, b1 y b2`) son representados como matrices, que en un primer momento contienen valores iniciales aleatorios. \n",
        "can also be represented as matrices, initialized as random values. \n",
        "La primera fila de `w` y el primer elemento de `b` son los coeficientes necesarios para calcular la primera variable, i.e., la cosecha de manzanas, y de forma similar la segunda para las naranjas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0-el_zmrLy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3602991-0271-476c-9f59-f54456af9062"
      },
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0505,  1.0754,  1.2567],\n",
            "        [ 0.5823, -0.7131,  0.0998]], requires_grad=True)\n",
            "tensor([-2.2784,  0.5465], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CDG649GrLy-"
      },
      "source": [
        "`torch.randn` crea un tensor con las dimensiones dadas con elementos tomados de forma aleatoria de una [distribución normal](https://en.wikipedia.org/wiki/Normal_distribution) con media 0 y desviación estandard 1.\n",
        "\n",
        "Por tanto, nuestro *modelo* es real y simplemente una función que realiza una multiplicación de matrices entre las entradas `inputs` y los pesos `w` (transpuestos) y añade el factor bias `b` (replicado para cada observación, diferente para cada target).\n",
        "\n",
        "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n",
        "\n",
        "Empelando las operaciones disponibles en Pytorch, podemos definir el modelo como sigue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZnQB-BBrLy-"
      },
      "source": [
        "def model(x):\n",
        "    return x @ w.t() + b"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7Ym5lihrLy-"
      },
      "source": [
        "`@` representa la multuiplicación de matrices en PyTorch, y el método `.t` devuelve un tensor transpuesto.\n",
        "\n",
        "La matriz obtenida al emplear los datos de entrada con los coeficientes del modelo es un conjunto de predicciones para las variables objetivo *targets*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg7Ymw0PrLy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc209f4-21e4-4310-d773-065dc8add9c4"
      },
      "source": [
        "# Genero predicciones (iniciales)\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[120.1250,  -0.4277],\n",
            "        [168.1900,  -2.8246],\n",
            "        [210.3215, -38.5539],\n",
            "        [ 85.3100,  32.9752],\n",
            "        [185.4446, -20.7419]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkH2oYmmrLzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6ec272-c088-4675-9eaf-47234c5c3377"
      },
      "source": [
        "# Comparamos con los targets reales\n",
        "print(targets)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZGtGJcjrLzA"
      },
      "source": [
        "Podemos ver una gran diferencia entre las predicciones obtenidas inicialmente y los valores reales. Esto ocurre porque los pesos y bias empleados han sido inicializados aleatoriamente y no podemos esperar que esos valores se correspondan y funcionen bien directamente. Un modelo inicializado aleatoriamente no está preparado para funcionar. Se trata simplemente de un inicio.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KmMqA8IrLzA"
      },
      "source": [
        "## Función de pérdida o de coste\n",
        "\n",
        "Antes de mejorar el modelo, necesitamos evaluar como de bien está funcionando. Para ello comparamos los resultados obtenidos con los resultados que se deberían obtener. En este caso vamos a emplear como función evluadora el error cuadrático medio o **mean squared error** (MSE). \n",
        "Desglosando el pseeudo código para calcularlo sería algo así:\n",
        "* Calculamos la diferencia entre las dos matrices(`preds` y `targets`).\n",
        "* Elevamos al cuadrado todos los elementos y de esa forma evitamos valores negativos. \n",
        "* Calculamos la media de los elementos en una matriz resultante.\n",
        "\n",
        "El resultado de este cálculo es un único número (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0fTNoWxrLzB"
      },
      "source": [
        "# MSE \n",
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D95gt0_CrLzB"
      },
      "source": [
        "`torch.sum` retorna la suma de todos los elementos de un tensor. El método `.numel` retorna el número de elementos de un tensor. \r\n",
        "\r\n",
        "Calculamos el MSE para las predicciones que hemos obtenidos con nuestro modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63YeUzDTrLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee888902-0d6e-4509-e4bb-c3d6cd9d2672"
      },
      "source": [
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9557.3330, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cprvF2KhrLzC"
      },
      "source": [
        "Así es como podemos interpretar el resultado: *de media, cada elemento en la predicción difiere de su valor correcto la raíz cuadrada del error obtenido*.\r\n",
        "Y eso es bastante malo, dado que los resultados que pretendemos predecir están en un rango de entre 50-200. El resultado se suele llamar *loss* porque implica la pérdida que introduce el modelo entre lo que obtenemos y lo que deberíamos obtener. Cuanto **menor es la pérdida** o error, **mejor es el modelo**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI0qiKAFrLzD"
      },
      "source": [
        "## Cálculo de gradientes\n",
        "\n",
        "Con Pytorch podemos calcular automáticamente los gradientes o derivadas del error con respecto de los pesos y del bias, porque hemos definido el parámetro `requires_grad` a `True`. Vamos a ver lo útil que resulta esta funcionalidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beq8p1gTrLzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "f8e4e16d-902e-46cc-ec1b-b6732cc240bf"
      },
      "source": [
        "# Calculamos gradientes\n",
        "loss.backward()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7523c31b7726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculamos gradientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7BcKtcUrLzD"
      },
      "source": [
        "Los gradientes están ahora guardados en la propiedad `.grad` de cada tensor. Nótese que la derivada del error w.r.t. a una matriz de pesos es una matriz también de las mismas dimensiones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ZMorGtrLzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ed8213-1eb3-444a-9a12-65e883232a07"
      },
      "source": [
        "# Gradients for weights\n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0505,  1.0754,  1.2567],\n",
            "        [ 0.5823, -0.7131,  0.0998]], requires_grad=True)\n",
            "tensor([[  6541.3359,   6968.6372,   4349.5547],\n",
            "        [ -7913.4341, -10086.3457,  -5910.8286]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1ZnLVvrLzE"
      },
      "source": [
        "## Ajuste de pesos y bias para reducir el error\n",
        "\n",
        "La pérdida es una [función cuadrática](https://en.wikipedia.org/wiki/Quadratic_function) de nuestros pesos y biases,  y nuestro objetivo es encontrar el conjunto de pesos donde la pérdida sea la más baja. Si dibujamos un gráfico de la pérdida con respecto a cualquiera de los pesos y bias, tendría el aspecto de la figura que se muestra abajo. Un importante detalle sobre cálculo es que el gradiente indica precisamente el ratio de cambio de la pérdida, es decir, la [pendiente](https://en.wikipedia.org/wiki/Slope) con respecto a los pesos y biases.\n",
        "\n",
        "Si el gradiente es **positivo**\n",
        "\n",
        "* **incrementar** el peso de esa variable ligeramente **incrementará** el error (*loss*) \n",
        "* **reducir** el peso ligeramente **reducirá** el error.\n",
        "\n",
        "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)\n",
        "\n",
        "Si el gradiente es **negativo**:\n",
        "\n",
        "* **incrementar** el peso de esa variable ligeramente **reducirá** el error (*loss*) \n",
        "* **reducir** el peso ligeramente **aumentará** el error.\n",
        "\n",
        "![negative=gradient](https://i.imgur.com/dvG2fxU.png)\n",
        "\n",
        "El incremento o reducción del error cambiando el peso de un elemento es proporcional al gradiente del error con respecto a dicho elemento (*variable*). \n",
        "Esta observación supone la base del algoritmo de optimización por *descenso de gradiente* que será el que emplearemos para mejorar nuestro modelo (por  _descenso_ a lo largo del _gradiente_).\n",
        "\n",
        "Dadas las relaciones descritas entre incremento/reducción del peso e incremento reducción del error, la forma en que podemos reducirlo consistirá en **restar** al peso de cada variable una pequeña cantidad proporcional al gradiente con respecto a dicha variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afl_XeJBrLzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b6d872-9748-4367-c549-fee0ab987894"
      },
      "source": [
        "w\n",
        "w.grad"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  6541.3359,   6968.6372,   4349.5547],\n",
              "        [ -7913.4341, -10086.3457,  -5910.8286]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBNco83TrLzF"
      },
      "source": [
        "# Actualizamos los pesos y bias\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REY7fBs3rLzG"
      },
      "source": [
        "Como se puede observar, hemos multiplicado los gradientes obteenidos por un número muy pequeño (`10^-5` en este caso). Esto es para asegurar que no modificamos los pesos en cantidades muy grandes. Queremos ir tomando pequeños pasos hacia la dirección de descenso siempre, no un gran salto que nos pueda desviar. Este número es lo que llamamos el ratio de aprendizaje *learning rate* del algoritmo.\n",
        "\n",
        "Podemos usar `torch.no_grad` para indicar a PyTorch que no queremos que internamente vaya calculando gradientescuando actualizamos los pesos, ya que no es necesario y únicamente provocamos más carga computacional. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C_24VbFrLzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d6c47d-5d1e-4e58-8e85-b572cb6d8c09"
      },
      "source": [
        "# Verificamos que la pérdida se ha reducido (probablemente muy poco)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9557.3330, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVnMi-FrrLzG"
      },
      "source": [
        "A continuación, será necesario resetear los gradientes a cero empleando el   método `.zero_()`. Necesitamos hacer esto porque PyTorch acumula los gradientes. Si no lo hacemos, la próxima vez que invocamos el método `.backward` en la función de pérdida, los nuevos valores de gradientes se sumarían a los existentes, lo que llevaría a resultados incorrectos e inesperados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oXTtLdlrLzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e434cf2a-981a-402e-c1eb-aa03a0ddeff7"
      },
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBXlTCArrLzH"
      },
      "source": [
        "## Entrenamiento del modelo usando descenso de gradiente\n",
        "\n",
        "Como hemos visto, podemos reducir la pérdida y mejorar nuestro modelo empleando la técnica de descenso de gradiente. Así pues, podemos _entrenar_ el modelo siguiendo los siguientes pasos: \n",
        "\n",
        "1. Generamos predicciones\n",
        "\n",
        "2. Calculamos el error/pérdida\n",
        "\n",
        "3. Calculamos los gradientes c.r.a. los pesos y biases\n",
        "\n",
        "4. Ajustamos los pesos restando una pequeña cantidad proporcianal a los gradientes obtenidos\n",
        "\n",
        "5. Reseteamos los gradientes a cero para repetir la operación\n",
        "\n",
        "Vamos a implementar esto paso a paso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "betZe18grLzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a46cfcd-f136-40a7-ca1b-508b4cd0c0bf"
      },
      "source": [
        "# Generamos predicciones\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 97.4945,  29.7269],\n",
            "        [138.4510,  36.8976],\n",
            "        [175.2166,   9.1054],\n",
            "        [ 62.7524,  62.1688],\n",
            "        [156.9469,  17.8215]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCScDDI9rLzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f822a827-2354-4c07-f862-01ea85c77783"
      },
      "source": [
        "# Calculamos el error/pérdida\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4470.5186, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5rA2H86rLzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c408d5ca-23e7-4f50-e236-b9d789f2dbb8"
      },
      "source": [
        "# Calculamos los gradientes\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4205.4121,  4460.0181,  2801.1614],\n",
            "        [-4793.2354, -6714.4111, -3834.2856]])\n",
            "tensor([ 205.3287, -256.6851])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekrB7z46rLzJ"
      },
      "source": [
        "# Ajustamos los pesos\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlsdvI9brLzK"
      },
      "source": [
        "Veamos los pesos y biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2m6382rLzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2638d0-14b7-417a-e691-c010717fed9e"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2234,  0.8915,  1.1417],\n",
            "        [ 0.7885, -0.4442,  0.2563]], requires_grad=True)\n",
            "tensor([-2.2820,  0.5510], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNfv2tnnrLzK"
      },
      "source": [
        "Con los nuevos pesos y biases, el modelo tiene un error menor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_9o6GIrrLzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6f37c9-2cf4-47b0-897b-8b44ed716f50"
      },
      "source": [
        "# Calculamos la pérdida\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3302.2507, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ZUarC0rLzL"
      },
      "source": [
        "Podemos observar que tenemos una mejora significativa, ajustando los pesos y biases segun esta técnica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KWQ_1_rrLzL"
      },
      "source": [
        "## Entrenar durante múltiples ciclos/épocas (epochs)\n",
        "\n",
        "Para reducir el error aún más, podemos repetir el proceso de ajustar pesos y biases usando los gradientes múltiples veces. Cada iteración se llama ciclo o época (_epoch_). Vamos a entrenar el modelo 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEFGWWRBrLzM"
      },
      "source": [
        "for i in range(100):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEhIdxZZrLzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c635dfd2-0ac9-464f-af06-70dcfdbe6e57"
      },
      "source": [
        "# Calculamos el nuevo error\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(263.3372, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P8SPCQ2rLzN"
      },
      "source": [
        "\r\n",
        "El error ahora es bastante menor que en el momento inicial. Vamos a ver las nuevas predicciones y compremoslas con los valores target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMg3ZeRbrLzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057520c1-e0cc-4d80-9a32-758862476531"
      },
      "source": [
        "# Prediciones\n",
        "preds"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.7639,  77.7144],\n",
              "        [ 84.7992, 103.6490],\n",
              "        [113.4353, 114.2801],\n",
              "        [ 21.2597,  79.3174],\n",
              "        [105.8755,  99.7427]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zULhmNirLzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234e5e06-a0f0-47d4-afb1-4738ae864cb2"
      },
      "source": [
        "# Targets\n",
        "targets"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4C2tOm4rLzO"
      },
      "source": [
        "Observamos que las predicciones son ahora bastante cercanas a los objetivos. Podemos mejorar estos resultados entrenando más ciclos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nSexto8rLzR"
      },
      "source": [
        "## Regresión lineal empleando las funciones propias de Pytorch\n",
        "\n",
        "Hasta ahora hemos implementado la regresión lineal y el descenso de gradiente empleando operaciones básicas sobre tensores. Sin embargo, dado que estas operaciones son un patrón común en deep learning, Pytorch provee una serie de **funciones y clases propias** específicamente preparadas para facilitar la creación y entrenamiento con tan solo unas cuantas líneas de código. \n",
        "\n",
        "Empezaremos importando el paqete `torch.nn` de PyTorch, el cual contiene las clases de utilidad para construir redes neuronales (_neural networks_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqm585tErLzR"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZgYP8ZsrLzR"
      },
      "source": [
        "Igual que antes, vamos a representar las entradas y salidas como matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Agf0fskrLzR"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YSJX-qQrLzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbc8dc3-db99-439d-e8ec-c2ec1f954989"
      },
      "source": [
        "inputs"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 74.,  66.,  43.],\n",
              "        [ 91.,  87.,  65.],\n",
              "        [ 88., 134.,  59.],\n",
              "        [101.,  44.,  37.],\n",
              "        [ 68.,  96.,  71.],\n",
              "        [ 73.,  66.,  44.],\n",
              "        [ 92.,  87.,  64.],\n",
              "        [ 87., 135.,  57.],\n",
              "        [103.,  43.,  36.],\n",
              "        [ 68.,  97.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxL_xNkbrLzS"
      },
      "source": [
        "Vamos a usar 15 observaciones de entrenamiento para ilustrar como trabajar con conjuntos más grandes en pequeños lotes (_batches_). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14AZDfjFrLzT"
      },
      "source": [
        "## Dataset y DataLoader\n",
        "\n",
        "Vamos a crear un `TensorDataset`, el cual va a permitir acceder a las filas de `inputs` y sus respectivos `targets` como tuplas, además de proveer APIs estandard para trabajar con muchos diferentes datasets en PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Mxl6D6rLzT"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4xRZFarLzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689e84c7-9a5b-45c8-d3f0-d9388ab2730d"
      },
      "source": [
        "# Define dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:5]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.],\n",
              "         [102.,  43.,  37.],\n",
              "         [ 69.,  96.,  70.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.],\n",
              "         [ 22.,  37.],\n",
              "         [103., 119.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGTUR0WKrLzU"
      },
      "source": [
        "`TensorDataset` nos permite acceder a una pequeña sección de los datos de entrenamiento usando la notación de índices de array (`[0:3]` en el código anterior). Devuelve una tupla con dos elementos. The first element contains the input variables for the selected rows, and the second contains the targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7myFSQiIrLzU"
      },
      "source": [
        "Vamos a crear también un  `DataLoader`, el cual irá dividiendo los datos en lotes (_batches_) de un tamaño predefinido mientras hace el entrenamiento. tambien aporta otras utilidades como el barajeo (_shuffling_) y el muestreo aleatorio de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIahdUBxrLzU"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvIVfKUirLzU"
      },
      "source": [
        "# Definimos el data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GSjfNphrLzV"
      },
      "source": [
        "Ahora podemos usar el data loader en un bucle `for`. Veamos un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZVM1j_CrLzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7687ea56-6195-497b-d270-c8a712eb9234"
      },
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 87., 134.,  58.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 74.,  66.,  43.]])\n",
            "tensor([[119., 133.],\n",
            "        [ 21.,  38.],\n",
            "        [ 80., 102.],\n",
            "        [ 56.,  70.],\n",
            "        [ 57.,  69.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBYpzThrLzV"
      },
      "source": [
        "En cada iteración, el data loader devuelve un lote de datos con el tamaño indicado. Si `shuffle` es `True`, \"barajará\" los datos antes de crear los lotes. Esto ayuda a alatorizar las entradas al algoritmo de optimización, lo cual redunda en una reducción del error más rápida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plceojdqrLzW"
      },
      "source": [
        "## nn.Linear\n",
        "\n",
        "En lugar de inicializar los pesos y biases manualmente, podemos definir el modelo usando la clase `nn.Linear` de PyTorch, la cual lo hace automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmOcrDJArLzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b4d853-d56b-4eb2-936d-b12da42749b1"
      },
      "source": [
        "# Define modelo\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3385, -0.1156,  0.0919],\n",
            "        [ 0.5262, -0.5632, -0.3295]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1045,  0.1059], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpXQNIXFJCy-"
      },
      "source": [
        "**NOTA IMPORTANTE:** \r\n",
        "*La clase \"nn.Linear\" empleada no se refiere directamente a una regresion lineal. En realidad lo que describe es un tipo de red neuronal empleado. En concreto este es un modelo en el que las capas estan totalmente conectadas unas con otras, denominadas \"fully connected\" o \"dense\" (de forma similar a Keras). Más adelante veremos que los modelos de redes neuronales pueden estar compuestos de capas de este tipo, de capas convolucionales y otros tipos.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFyWBxK9rLzW"
      },
      "source": [
        "Los modelos en PyTorch tienen un método muy útil llamado `.parameters`, el cual retorna una lista conteniendo todas las matrices de pesos y biases presentes en ese modelo. Para nuestro modelo de regresion lineal, tenemos una matriz de pesos y otra de biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXgzbBafrLzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfeea840-93df-45e4-90c2-f105d257ddcd"
      },
      "source": [
        "# Parametros\n",
        "list(model.parameters())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.3385, -0.1156,  0.0919],\n",
              "         [ 0.5262, -0.5632, -0.3295]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1045,  0.1059], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgMML2MZrLzX"
      },
      "source": [
        "Ahora podemos usar el modelo generado para realizar nuestras predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGHn-WjwrLzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1f43ff-6bd8-43af-c53f-635054078fd3"
      },
      "source": [
        "# Genera prediciones\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-28.6062, -13.3832],\n",
              "        [-35.1965, -22.6579],\n",
              "        [-39.7095, -48.6916],\n",
              "        [-36.2003,  17.3698],\n",
              "        [-28.1229, -40.7167],\n",
              "        [-28.8292, -12.2938],\n",
              "        [-34.9890, -22.4243],\n",
              "        [-39.9561, -48.4950],\n",
              "        [-35.9774,  16.2804],\n",
              "        [-27.6925, -41.5724],\n",
              "        [-28.3988, -13.1495],\n",
              "        [-35.4194, -21.5686],\n",
              "        [-39.9169, -48.9253],\n",
              "        [-36.6306,  18.2255],\n",
              "        [-27.9000, -41.8061]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOIc9oSQrLzY"
      },
      "source": [
        "## Funcion de error o pérdida \n",
        "\n",
        "En lugar de definir una función de error manualmente, podemos usar la función propia de Pytorch `mse_loss`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSJcJY6orLzY"
      },
      "source": [
        "# Importa nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWYGEHSarLzZ"
      },
      "source": [
        "El paquete `nn.functional` contiene muchas otras y útiles funciones de cálculo de error entre otras utilidades. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljPEP0srLzZ"
      },
      "source": [
        "# Definimos la función de loss\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XneC34O9rLzZ"
      },
      "source": [
        "Calculamos el error para las predicciones de nuestro modelo de la siguiente forma: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqM8TDhrLzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5d970b-3b4c-4934-c811-3b54288ede98"
      },
      "source": [
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(14732.4092, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29J0-Tn6rLza"
      },
      "source": [
        "## Optimización\n",
        "\n",
        "En lugar de manualmente manipular los pesos y biases del modelo a través de los gradientes, podemos usar el optimizador propio `optim.SGD`. SGD es la abreviatura de \"stochastic gradient descent\". El término estocástico indica que las muestras son seleccionadas en lotes aleatorios en lugar de individualmente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgOLXduIrLza"
      },
      "source": [
        "# Define optimizador\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAnliLuxrLza"
      },
      "source": [
        "Obsérvese que los parámetros del modelo son pasados como argumento a `optim.SGD` de forma que el optimizador sepa qué matrices de pesos y biases osn las que tiene que ir modificando durante el proceso de actualización. También podemos especificar el ratio de aprendizaje \"lr\" que controla la cantidad con que los parametros son modificados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAYgy6btrLzb"
      },
      "source": [
        "## Entrenamiento del modelo\n",
        "\n",
        "Vamos ahora a realizar el entrenamiento del modelo. Seguiremos el mismo proceso que ya hemos visto para implementar el descenso de gradiente:\n",
        "\n",
        "1. Generamos predicciones\n",
        "\n",
        "2. Calculamos el error/pérdida\n",
        "\n",
        "3. Calculamos los gradientes c.r.a. los pesos y biases\n",
        "\n",
        "4. Ajustamos los pesos restando una pequeña cantidad proporcianal a los gradientes obtenidos\n",
        "\n",
        "5. Reseteamos los gradientes a cero para repetir la operación\n",
        "\n",
        "El único cambio es que ahora vamos a trabajar con lotes de datos en lugar de emplear el dataset de entrenamiento completo en cada iteracion. \n",
        "\n",
        "Vamos a definir una función `fit` que realizará el entrenamiento de esa forma para un número dado de ciclos (_epochs_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5rMu6BPrLzb"
      },
      "source": [
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repetir para el número especificado de epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Entrena por lotes de datos\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            # 1. Generamos predicciones\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculamos el error/pérdida\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Calculamos los gradientes\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Actualizamos los parámetros\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reseteamos los gradientes a cero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Imprimimos el progreso\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKYTBgY1rLzb"
      },
      "source": [
        "Algunso detalles sobre la función definida: \n",
        "\n",
        "* Usamos el data loader definido previamente para obtener lotes de datos para cada iteración.\n",
        "\n",
        "* En lugar de actualizar los parametros (pesos y biases) manualmente, usamos `opt.step` para realiarlo y `opt.zero_grad` para resetear a cer los gradientes. \n",
        "\n",
        "* Se ha añadido unas líneas de log que imprimen el error del último lote entrenado cada 10 iteraciones, de forma que podemos seguir en progreso de entrenamiento. `loss.item` retorna el valor actual almacenado en el tensor de error _loss_.\n",
        "\n",
        "Vamos a entrenar 100 veces:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-JEYySrLzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a01fc2d-12fe-4936-90f4-148144a26170"
      },
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 802.5421\n",
            "Epoch [20/100], Loss: 219.4365\n",
            "Epoch [30/100], Loss: 344.1298\n",
            "Epoch [40/100], Loss: 188.6919\n",
            "Epoch [50/100], Loss: 288.3336\n",
            "Epoch [60/100], Loss: 170.7863\n",
            "Epoch [70/100], Loss: 68.6745\n",
            "Epoch [80/100], Loss: 119.7530\n",
            "Epoch [90/100], Loss: 110.3825\n",
            "Epoch [100/100], Loss: 45.2911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JExdgXXrLzc"
      },
      "source": [
        "Let's generate predictions using our model and verify that they're close to our targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45dkmCS8rLzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d626bf-ad7c-44de-9b20-62cabea07ec1"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.7858,  72.4513],\n",
              "        [ 81.4282,  97.6197],\n",
              "        [117.6779, 134.8429],\n",
              "        [ 26.0864,  50.1878],\n",
              "        [ 97.7545, 106.2815],\n",
              "        [ 56.6612,  71.6061],\n",
              "        [ 81.1369,  97.1029],\n",
              "        [117.9288, 135.1887],\n",
              "        [ 27.2110,  51.0330],\n",
              "        [ 98.5878, 106.6098],\n",
              "        [ 57.4944,  71.9344],\n",
              "        [ 80.3036,  96.7745],\n",
              "        [117.9693, 135.3597],\n",
              "        [ 25.2531,  49.8595],\n",
              "        [ 98.8792, 107.1267]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yKivQFPrLzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac69796-c1b3-440d-d9cc-7a1145779fd2"
      },
      "source": [
        "# Compare with targets\n",
        "targets"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nydotCibrLzd"
      },
      "source": [
        "Ahora las predicciones son bastante cercanas a nuestros valores objetivos. Hemos entrenado un modelo razonablemente bueno que nos permite predecir la cosecha a partir de tres variables temperatura, lluvias y humedad en una región. Podemos emplear el modelo para realizar predicciones para otra región pasandole un lote con una sola fila como entrada: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ONCHxZ3rLze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d4a998-a8e3-47ad-b305-234b3f322e01"
      },
      "source": [
        "model(torch.tensor([[75, 63, 44.]]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[54.4118, 69.3901]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YO3RYSarLze"
      },
      "source": [
        "El modelo predice una cosecha de 54.3 tons/hect. de manzanas, y 68.3 tons/hect. de naranjas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QOf-HEltUP"
      },
      "source": [
        "## Fin del Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDr1zYmBkRV"
      },
      "source": [
        "Referencias y modelos empleados para el Notebook: \r\n",
        "\r\n",
        "*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \r\n",
        "*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\r\n",
        "*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\r\n",
        "*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\r\n",
        "*   Tutoriales y notebooks del curso \"Deep Learning with Pytorch: Zero to GANs\" de [Aakash N S](https://jovian.ai/aakashns)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}