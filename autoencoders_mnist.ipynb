{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "autoencoders_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvallalta/ia3/blob/main/autoencoders_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoEFSXNDN4ju"
      },
      "source": [
        "# Entrenamiento de Autoencoders con datos de dígitos (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKwAmM2mNgEF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XssZbuDSOEI1"
      },
      "source": [
        "## Carga y procesamiento de los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0fBxO1COFIl",
        "outputId": "1ccb7d14-f351-43ba-a218-13a54ac7db78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Carga\n",
        "(X_train, y_train), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "print(' -Entradas Entrenamiento:', X_train.shape)\n",
        "print(' -Entradas Test:', X_test.shape)\n",
        "\n",
        "# Normalización\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "print('Cambio de dimensiones para ajustar a la entrada de un Perceptrón:')\n",
        "x_shape = X_train.shape\n",
        "X_train = X_train.reshape(x_shape[0], x_shape[1]*x_shape[2])\n",
        "X_test = X_test.reshape(len(X_test), x_shape[1]*x_shape[2])\n",
        "print(' -Entradas Entrenamiento:', X_train.shape)\n",
        "print(' -Entradas Test:', X_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            " -Entradas Entrenamiento: (60000, 28, 28)\n",
            " -Entradas Test: (10000, 28, 28)\n",
            "Cambio de dimensiones para ajustar a la entrada de un Perceptrón:\n",
            " -Entradas Entrenamiento: (60000, 784)\n",
            " -Entradas Test: (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9l_RuFtOc9n"
      },
      "source": [
        "## Autoencoder profundo\n",
        "### Creación del autoencoder\n",
        "Vamos a crear un autoencoder que codifique y decodifique la entrada de 728 píxeles en la siguiente secuencia de dimensiones:\n",
        "\n",
        "784 → 128 → 64 → 32 → 64 → 128 → 784"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58lt8AZiK_Gc"
      },
      "source": [
        "# Forma profesor\n",
        "# Tamaño de nuestra representación codificada\n",
        "encoding_dim = 32  # Factor de compresión = 24.5 (dado que la entrada es de tamaño 784)\n",
        "\n",
        "# Definimos las capas para la entrada, el encoder y el decoder:\n",
        "# Capa de entrada\n",
        "input_img = Input(shape=(784,), name='Input')\n",
        "\n",
        "# Capas del encoder\n",
        "encoder1 = Dense(128, activation='relu', name='Encoder1')\n",
        "encoder2 = Dense(64, activation='relu', name='Encoder2')\n",
        "encoder3 = Dense(encoding_dim, activation='relu', name='Encoder3')\n",
        "\n",
        "# Capas del decoder\n",
        "decoder1 = Dense(64, activation='relu', name='Decoder1')\n",
        "decoder2 = Dense(128, activation='relu', name='Decoder2')\n",
        "decoder3 = Dense(784, activation='sigmoid', name='Decoder3')\n",
        "\n",
        "#       Autoencoder\n",
        "# --------------------------\n",
        "# \"encoded\" es la representación codificada de la entrada (cada vez más comprimida)\n",
        "encoded = encoder1(input_img)\n",
        "encoded = encoder2(encoded)\n",
        "encoded = encoder3(encoded)\n",
        "\n",
        "# \"decoded\" es la reconstrución de la entrada a partir de la entrada codificada\n",
        "decoded = decoder1(encoded)\n",
        "decoded = decoder2(decoded)\n",
        "decoded = decoder3(decoded)\n",
        "\n",
        "# Modelo que reconstruye una entrada\n",
        "autoencoder = tf.keras.Model(input_img, decoded)\n",
        "\n",
        "# Visualizar arquitectura y dimensiones\n",
        "print(f\"{'*'*65}\\n\\t\\t\\tAutoencoder\\n{'*'*65}\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi1nIAg7Oafu",
        "outputId": "71f19445-b57e-49cb-e047-16b20abc5eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tamaño de nuestra representación codificada\n",
        "encoding_dim = 32  # Factor de compresión = 24.5 (dado que la entrada es de tamaño 784)\n",
        "\n",
        "# Definimos las capas para la entrada, el encoder y el decoder:\n",
        "# Capa de entrada\n",
        "input_img = Input(shape=(784, ), name='Input')\n",
        "\n",
        "# Capas del encoder\n",
        "x = Dense(128, activation='relu', name='Encoder128')(input_img)\n",
        "x = Dense(64, activation='relu', name='Encoder64')(x)\n",
        "encoder = Dense(32, activation='relu', name='Encoder32')(x)\n",
        "\n",
        "# Capas del decoder\n",
        "x = Dense(64, activation='relu', name='Decoder64')(encoder)\n",
        "x = Dense(128, activation='relu', name='Decoder128')(x)\n",
        "decoded = Dense(784, activation='softmax', name='Ouput')(x)\n",
        "\n",
        "#       Autoencoder\n",
        "# --------------------------\n",
        "# \"encoded\" es la representación codificada de la entrada (cada vez más comprimida)\n",
        "#encoded = . . .\n",
        "#      .\n",
        "#      .\n",
        "#      .\n",
        "\n",
        "\n",
        "# \"decoded\" es la reconstrución de la entrada a partir de la entrada codificada\n",
        "#decoded = . . .\n",
        "#      .\n",
        "#      .\n",
        "#      .\n",
        "\n",
        "# Modelo que reconstruye una entrada\n",
        "autoencoder = tf.keras.Model(input_img, decoded)\n",
        "encoder = tf.keras.Model(input_img, encoder)\n",
        "\n",
        "# Visualizar arquitectura y dimensiones\n",
        "print(f\"{'*'*65}\\n\\t\\t\\tAutoencoder\\n{'*'*65}\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************************************************************\n",
            "\t\t\tAutoencoder\n",
            "*****************************************************************\n",
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "Encoder128 (Dense)           (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "Encoder64 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "Encoder32 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "Decoder64 (Dense)            (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "Decoder128 (Dense)           (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "Ouput (Dense)                (None, 784)               101136    \n",
            "=================================================================\n",
            "Total params: 222,384\n",
            "Trainable params: 222,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIRkVdivQ8qL"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nblNVZF3Q8Cl",
        "outputId": "81502d6f-5286-4bdb-b3d8-daee199a5a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "hist= autoencoder.fit(input_img, \n",
        "                      decoded,\n",
        "                      epochs=50,\n",
        "                      batch_size=256,\n",
        "                      shuffle=True,\n",
        "                      validation_data=(input_img, decoded))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b34ece25f123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       validation_data=(input_img, decoded))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud9za_Rx3Z2u"
      },
      "source": [
        "### Evaluación y visualización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmX4QIq59nKc"
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Error')\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.legend(['Entrenamiento', 'Validación']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JAmGvpcs0_r"
      },
      "source": [
        "# Vamos a crear ahora por un lado un modelo para el encoder y otro para el decoder\n",
        "#          Encoder\n",
        "# ------------------------\n",
        "encoder = tf.keras.Model(, )\n",
        "\n",
        "# Visualizar arquitectura y dimensiones\n",
        "print(f\"\\n{'*'*65}\\n\\t\\t\\tEncoder\\n{'*'*65}\")\n",
        "encoder.summary()\n",
        "\n",
        "# Codificamos y decodificamos algunos dígitos de ejemplo (datos de test)\n",
        "# -----------------------\n",
        "encoded_imgs = . . .\n",
        "decoded_imgs = . . .\n",
        " \n",
        "n_images = 10 \n",
        "plt.figure(figsize=(30, 4))\n",
        "for i in range(n_images):\n",
        "    # Entrada (original)\n",
        "    plt.subplot(3, n_images, i + 1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Codificación\n",
        "    plt.subplot(3, n_images, i + 1 + n_images)\n",
        "    plt.imshow(encoded_imgs[i].reshape(1, encoding_dim), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Entrada codificada')\n",
        "    \n",
        "    # Reconstrucción\n",
        "    plt.subplot(3, n_images, i + 1 + n_images + n_images)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Reconstrucción')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_F7bIhs3fCN"
      },
      "source": [
        "## Aplicación: Eliminación de ruido\n",
        "Para obtener un modelo capaz de eliminar ruido de las imágenes de dígitos vamos a entrenar un autoencoder que mapee imágenes de dígitos con ruido (entrada) a imágenes de dígitos \"limpias\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ms-kNx3tZG"
      },
      "source": [
        "# Añadimos ruido gaussiano (distribución normal) a las imágenes.\n",
        "noise_factor = 0.5\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
        "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
        "\n",
        "# Aseguramos que todos los pixeles queden en el rango [0, 1]\n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
        "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
        "\n",
        "# Dibujamos las imágenes con ruido\n",
        "n_images = 10\n",
        "plt.figure(figsize=(30, 3))\n",
        "for i in range(n_images):\n",
        "    plt.subplot(1, n_images, i+1)\n",
        "    plt.imshow(X_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP5x2WdhAZo7"
      },
      "source": [
        "### Creación del modelo y entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnDxX8xYAY6d"
      },
      "source": [
        "# Creación del modelo\n",
        "encoding_dim = 32\n",
        "autoencoder = tf.keras.models.Sequential()\n",
        "#       .\n",
        "#       .\n",
        "#       .\n",
        "\n",
        "# Entrenamiento\n",
        "autoencoder.compile(optimizer='adam', loss='')\n",
        "hist= autoencoder.fit(, \n",
        "                      ,\n",
        "                      epochs=50,\n",
        "                      batch_size=256,\n",
        "                      shuffle=True,\n",
        "                      validation_data=(, ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJVpDdoJC27n"
      },
      "source": [
        "### Evaluación y visualización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr5V5UOgC-OV"
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Error')\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.legend(['Entrenamiento', 'Validación'])\n",
        "\n",
        "predictions = autoencoder.predict(X_test)\n",
        "n_images = 10 \n",
        "plt.figure(figsize=(30, 8))\n",
        "for i in range(n_images):\n",
        "    # Entrada (original)\n",
        "    plt.subplot(3, n_images, i + 1)\n",
        "    plt.imshow(X_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Reconstrucción\n",
        "    plt.subplot(3, n_images, i + 1 + n_images)\n",
        "    plt.imshow(predictions[i].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Reconstrucción')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0igVc6GhgJF"
      },
      "source": [
        "## Autoencoder Variacional\n",
        "### Creación del Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3MI8YrlBK_h"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    # Capas del encoder\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "\n",
        "  def call(self, inputs, training=None, mask=None):\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3OWaMRyyfff"
      },
      "source": [
        "### Creación de la capa que representa la distribución normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9spiM1SnyrZH"
      },
      "source": [
        "class NormalDistribution(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(NormalDistribution, self).__init__()\n",
        "    \n",
        "    # Capas\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "\n",
        "  def call(self, inputs, training=None, mask=None):\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    return z_mean, z_log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aACxBKvohkXO"
      },
      "source": [
        "\n",
        "### Creación de la capa de muestreo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qtElIDFhpUr"
      },
      "source": [
        "class Reparametrize(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Usa (z_mu, z_log_var) para muestrear z (el vector que \n",
        "  representa el dígito codificado)\n",
        "  \"\"\"\n",
        "  def call(self, inputs):\n",
        "    z_mu, z_log_var = inputs\n",
        "    \n",
        "    # Extraemos dimensiones (del batch y del espacio codificado)\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    \n",
        "    # Muestreamos de una distribucion normal ϵ: con dimensiones (batch, dim_spacio_codificado)\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    \n",
        "    # Transformamos log(σ^2) en σ \n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "\n",
        "    # Truco de re-parametrización\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    \n",
        "    return reparametrization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL1FirsoCtKy"
      },
      "source": [
        "### Creación del Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-iYljRwBnIz"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    # Capas del decoder\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "\n",
        "  def call(self, inputs,  training=None, mask=None):\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKQzo-txsLoc"
      },
      "source": [
        "### Creación de la función de coste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLcf71NqsKra"
      },
      "source": [
        "class LossVAE(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Función de error custom: suma del término de reconstrucción y \n",
        "  el término de regularización KL divergence\n",
        "  \"\"\"\n",
        "  def call(self, inputs):\n",
        "    y_true, y_pred, z_mean, z_log_var = inputs\n",
        "    \n",
        "    # Error de reconstrucción (usa categorical_crossentroy)\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "    \n",
        "    # Divergencia KL\n",
        "    #       .\n",
        "    #       .\n",
        "    #       .\n",
        "  \n",
        "    return reconstruction_loss, kl_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx9qBX37CzeY"
      },
      "source": [
        "### Creación del Autoencoder Variacional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIPYLV1uhmHj"
      },
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super(VAE, self).__init__()\n",
        "      # Capas del VAE\n",
        "      #       .\n",
        "      #       .\n",
        "      #       .\n",
        "\n",
        "    def call(self, inputs,  training=None, mask=None):\n",
        "      #       .\n",
        "      #       .\n",
        "      #       .\n",
        "      return (z_mean, z_log_var, z), decoded\n",
        "\n",
        "    def train_step(self, data):\n",
        "      with tf.GradientTape() as tape:\n",
        "        # Propagación hacia delante\n",
        "        #       .\n",
        "        #       .\n",
        "        #       .\n",
        "        total_loss = (784 * reconstruction_loss) + (2 * kl_loss)\n",
        "      \n",
        "      # Retro-propagación\n",
        "      grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "      \n",
        "      # Actualización de los pesos\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "      \n",
        "      return {\"reconstruction_loss\": reconstruction_loss,\n",
        "              \"kl_loss\": kl_loss,\n",
        "              \"total_loss\": total_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4k9tjKAQ7wo"
      },
      "source": [
        "### Entrenamiento del Autoencoder Variacional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYCno6nA4vGU"
      },
      "source": [
        "vae = VAE()\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
        "vae.fit(X_train, epochs=30, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvUZD_JsRIE_"
      },
      "source": [
        "### Muestra de Dígitos Generados con el Autoencoder Varacional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbk67dUWRo6v"
      },
      "source": [
        "def plot_latent(model, fig_size=15, scale=3.):\n",
        "    n = 30\n",
        "    digit_size = 28\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # Creamos un grid 2D linealmente espaciado correspondiente a\n",
        "    # los dígitos en el espacio codificado\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "            # Para cada coordenada 2D del espacio codificado, \n",
        "            # usamos el decoder para reconstruir/generar una imagen nueva.\n",
        "            x_decoded = model.decoder(z_sample).numpy()\n",
        "            digit = x_decoded.reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size : (i + 1) * digit_size,\n",
        "                   j * digit_size : (j + 1) * digit_size] = digit\n",
        "\n",
        "    plt.figure(figsize=(fig_size, fig_size))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range + 1\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_label_clusters(model, data, labels, fig_size=15, scale=3.):\n",
        "    # Dibujamos un plot 2D the los dígitos y sus clases en el espacio codificado\n",
        "    encoded = model.encoder(data)\n",
        "    z_mean, _ = model.normal_distribution(encoded)\n",
        "    plt.figure(figsize=(fig_size, fig_size))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.xlim((-scale, scale))\n",
        "    plt.ylim((-scale, scale)) \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaGwFRoRY2vU"
      },
      "source": [
        "plot_latent(vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgOm9S0jk5S3"
      },
      "source": [
        "plot_label_clusters(vae, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}