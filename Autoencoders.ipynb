{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/lF7I0avosY/v9b3qxdb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvallalta/ia3/blob/main/Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaeCd1aDj9Dd"
      },
      "source": [
        "# Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gIjURFtlzu-"
      },
      "source": [
        "Utilidades"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tx2Mx5bkUUG"
      },
      "source": [
        "from keras.callbacks import Callback\r\n",
        "\r\n",
        "#### CALLBACKS\r\n",
        "class CustomCallback(Callback):\r\n",
        "    \r\n",
        "    def __init__(self, run_folder, print_every_n_batches, initial_epoch, vae):\r\n",
        "        self.epoch = initial_epoch\r\n",
        "        self.run_folder = run_folder\r\n",
        "        self.print_every_n_batches = print_every_n_batches\r\n",
        "        self.vae = vae\r\n",
        "\r\n",
        "    def on_batch_end(self, batch, logs={}):  \r\n",
        "        if batch % self.print_every_n_batches == 0:\r\n",
        "            z_new = np.random.normal(size = (1,self.vae.z_dim))\r\n",
        "            reconst = self.vae.decoder.predict(np.array(z_new))[0].squeeze()\r\n",
        "\r\n",
        "            filepath = os.path.join(self.run_folder, 'images', 'img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\r\n",
        "            if len(reconst.shape) == 2:\r\n",
        "                plt.imsave(filepath, reconst, cmap='gray_r')\r\n",
        "            else:\r\n",
        "                plt.imsave(filepath, reconst)\r\n",
        "\r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        self.epoch += 1\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\r\n",
        "    '''\r\n",
        "    Wrapper function to create a LearningRateScheduler with step decay schedule.\r\n",
        "    '''\r\n",
        "    def schedule(epoch):\r\n",
        "      new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\r\n",
        "        \r\n",
        "      return new_lr\r\n",
        "    return LearningRateScheduler(schedule)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oXfAKbll2om"
      },
      "source": [
        "Personalizamos la clase Autoecoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWj6FIOdj280"
      },
      "source": [
        "\r\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\r\n",
        "from keras.models import Model\r\n",
        "from keras import backend as K\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ModelCheckpoint \r\n",
        "from keras.utils import plot_model\r\n",
        "\r\n",
        "#from utils.callbacks import CustomCallback, step_decay_schedule\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "\r\n",
        "\r\n",
        "class Autoencoder():\r\n",
        "    def __init__(self\r\n",
        "        , input_dim\r\n",
        "        , encoder_conv_filters\r\n",
        "        , encoder_conv_kernel_size\r\n",
        "        , encoder_conv_strides\r\n",
        "        , decoder_conv_t_filters\r\n",
        "        , decoder_conv_t_kernel_size\r\n",
        "        , decoder_conv_t_strides\r\n",
        "        , z_dim\r\n",
        "        , use_batch_norm = False\r\n",
        "        , use_dropout = False\r\n",
        "        ):\r\n",
        "\r\n",
        "        self.name = 'autoencoder'\r\n",
        "\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.encoder_conv_filters = encoder_conv_filters\r\n",
        "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\r\n",
        "        self.encoder_conv_strides = encoder_conv_strides\r\n",
        "        self.decoder_conv_t_filters = decoder_conv_t_filters\r\n",
        "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\r\n",
        "        self.decoder_conv_t_strides = decoder_conv_t_strides\r\n",
        "        self.z_dim = z_dim\r\n",
        "\r\n",
        "        self.use_batch_norm = use_batch_norm\r\n",
        "        self.use_dropout = use_dropout\r\n",
        "\r\n",
        "        self.n_layers_encoder = len(encoder_conv_filters)\r\n",
        "        self.n_layers_decoder = len(decoder_conv_t_filters)\r\n",
        "\r\n",
        "        self._build()\r\n",
        "\r\n",
        "    def _build(self):\r\n",
        "\r\n",
        "        ### THE ENCODER\r\n",
        "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\r\n",
        "\r\n",
        "        x = encoder_input\r\n",
        "\r\n",
        "        for i in range(self.n_layers_encoder):\r\n",
        "            conv_layer = Conv2D(\r\n",
        "                filters = self.encoder_conv_filters[i]\r\n",
        "                , kernel_size = self.encoder_conv_kernel_size[i]\r\n",
        "                , strides = self.encoder_conv_strides[i]\r\n",
        "                , padding = 'same'\r\n",
        "                , name = 'encoder_conv_' + str(i)\r\n",
        "                )\r\n",
        "\r\n",
        "            x = conv_layer(x)\r\n",
        "\r\n",
        "            x = LeakyReLU()(x)\r\n",
        "\r\n",
        "            if self.use_batch_norm:\r\n",
        "                x = BatchNormalization()(x)\r\n",
        "\r\n",
        "            if self.use_dropout:\r\n",
        "                x = Dropout(rate = 0.25)(x)\r\n",
        "\r\n",
        "        shape_before_flattening = K.int_shape(x)[1:]\r\n",
        "\r\n",
        "        x = Flatten()(x)\r\n",
        "        encoder_output= Dense(self.z_dim, name='encoder_output')(x)\r\n",
        "\r\n",
        "        self.encoder = Model(encoder_input, encoder_output)\r\n",
        "\r\n",
        "\r\n",
        "        ### THE DECODER\r\n",
        "        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\r\n",
        "\r\n",
        "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\r\n",
        "        x = Reshape(shape_before_flattening)(x)\r\n",
        "\r\n",
        "        for i in range(self.n_layers_decoder):\r\n",
        "            conv_t_layer = Conv2DTranspose(\r\n",
        "                filters = self.decoder_conv_t_filters[i]\r\n",
        "                , kernel_size = self.decoder_conv_t_kernel_size[i]\r\n",
        "                , strides = self.decoder_conv_t_strides[i]\r\n",
        "                , padding = 'same'\r\n",
        "                , name = 'decoder_conv_t_' + str(i)\r\n",
        "                )\r\n",
        "\r\n",
        "            x = conv_t_layer(x)\r\n",
        "\r\n",
        "            if i < self.n_layers_decoder - 1:\r\n",
        "                x = LeakyReLU()(x)\r\n",
        "                \r\n",
        "                if self.use_batch_norm:\r\n",
        "                    x = BatchNormalization()(x)\r\n",
        "                \r\n",
        "                if self.use_dropout:\r\n",
        "                    x = Dropout(rate = 0.25)(x)\r\n",
        "            else:\r\n",
        "                x = Activation('sigmoid')(x)\r\n",
        "\r\n",
        "        decoder_output = x\r\n",
        "\r\n",
        "        self.decoder = Model(decoder_input, decoder_output)\r\n",
        "\r\n",
        "        ### THE FULL AUTOENCODER\r\n",
        "        model_input = encoder_input\r\n",
        "        model_output = self.decoder(encoder_output)\r\n",
        "\r\n",
        "        self.model = Model(model_input, model_output)\r\n",
        "\r\n",
        "\r\n",
        "    def compile(self, learning_rate):\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "\r\n",
        "        optimizer = Adam(lr=learning_rate)\r\n",
        "\r\n",
        "        def r_loss(y_true, y_pred):\r\n",
        "            return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\r\n",
        "\r\n",
        "        self.model.compile(optimizer=optimizer, loss = r_loss)\r\n",
        "\r\n",
        "    def save(self, folder):\r\n",
        "\r\n",
        "        if not os.path.exists(folder):\r\n",
        "            os.makedirs(folder)\r\n",
        "            os.makedirs(os.path.join(folder, 'viz'))\r\n",
        "            os.makedirs(os.path.join(folder, 'weights'))\r\n",
        "            os.makedirs(os.path.join(folder, 'images'))\r\n",
        "\r\n",
        "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\r\n",
        "            pickle.dump([\r\n",
        "                self.input_dim\r\n",
        "                , self.encoder_conv_filters\r\n",
        "                , self.encoder_conv_kernel_size\r\n",
        "                , self.encoder_conv_strides\r\n",
        "                , self.decoder_conv_t_filters\r\n",
        "                , self.decoder_conv_t_kernel_size\r\n",
        "                , self.decoder_conv_t_strides\r\n",
        "                , self.z_dim\r\n",
        "                , self.use_batch_norm\r\n",
        "                , self.use_dropout\r\n",
        "                ], f)\r\n",
        "\r\n",
        "        self.plot_model(folder)\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "    def load_weights(self, filepath):\r\n",
        "        self.model.load_weights(filepath)\r\n",
        "\r\n",
        "    \r\n",
        "    def train(self, x_train, batch_size, epochs, run_folder, print_every_n_batches = 100, initial_epoch = 0, lr_decay = 1):\r\n",
        "\r\n",
        "        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\r\n",
        "        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\r\n",
        "\r\n",
        "        checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only = True, verbose=1)\r\n",
        "\r\n",
        "        callbacks_list = [checkpoint2, custom_callback, lr_sched]\r\n",
        "\r\n",
        "        self.model.fit(     \r\n",
        "            x_train\r\n",
        "            , x_train\r\n",
        "            , batch_size = batch_size\r\n",
        "            , shuffle = True\r\n",
        "            , epochs = epochs\r\n",
        "            , initial_epoch = initial_epoch\r\n",
        "            , callbacks = callbacks_list\r\n",
        "        )\r\n",
        "\r\n",
        "    def plot_model(self, run_folder):\r\n",
        "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\r\n",
        "        plot_model(self.encoder, to_file=os.path.join(run_folder ,'viz/encoder.png'), show_shapes = True, show_layer_names = True)\r\n",
        "        plot_model(self.decoder, to_file=os.path.join(run_folder ,'viz/decoder.png'), show_shapes = True, show_layer_names = True)\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ZD7Hj6kDt4"
      },
      "source": [
        "AE = Autoencoder(\r\n",
        "input_dim = (28,28,1)\r\n",
        ", encoder_conv_filters = [32,64,64, 64]\r\n",
        ", encoder_conv_kernel_size = [3,3,3,3]\r\n",
        ", encoder_conv_strides = [1,2,2,1]\r\n",
        ", decoder_conv_t_filters = [64,64,32,1]\r\n",
        ", decoder_conv_t_kernel_size = [3,3,3,3]\r\n",
        ", decoder_conv_t_strides = [1,2,2,1]\r\n",
        ", z_dim = 2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItWlaOqOmIcm"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ8nXY9-pB8X"
      },
      "source": [
        "# run params\r\n",
        "SECTION = 'vae'\r\n",
        "RUN_ID = '0001'\r\n",
        "DATA_NAME = 'digits'\r\n",
        "RUN_FOLDER = '/'\r\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\r\n",
        "\r\n",
        "if not os.path.exists(RUN_FOLDER):\r\n",
        "    os.mkdir(RUN_FOLDER)\r\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\r\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\r\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\r\n",
        "\r\n",
        "MODE =  'build' #'load' #"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSHJhVqpIGk",
        "outputId": "9c6e8b42-a84e-47c8-e8d7-ce9d496a3df2"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0BKWKRXqUD6"
      },
      "source": [
        "if MODE == 'build':\r\n",
        "    AE.save(RUN_FOLDER)\r\n",
        "else:\r\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5XbEgG9q1Hz"
      },
      "source": [
        "AE.encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH0MnpSmq5Td"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "BATCH_SIZE = 32\r\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hU2RO9-rQAZ"
      },
      "source": [
        "AE.compile(LEARNING_RATE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xo-1Kf7rbEW",
        "outputId": "c9bf8913-7dcf-4cea-ec6f-dc7fc04f6580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "AE.train(     \r\n",
        "    x_train[:1000]\r\n",
        "    , batch_size = BATCH_SIZE\r\n",
        "    , epochs = 200\r\n",
        "    , run_folder = RUN_FOLDER\r\n",
        "    , initial_epoch = INITIAL_EPOCH\r\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a79f66f15f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINITIAL_EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-9-7844d262bc8c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mcustom_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mlr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_decay_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mcheckpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights/weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-ae2dee56fbab>\u001b[0m in \u001b[0;36mstep_decay_schedule\u001b[0;34m(initial_lr, decay_factor, step_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnew_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'LearningRateScheduler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3jDwnghrem7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}