{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "04-Pytorch-con-GPU-CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "laOv0FJc3xJW",
        "n2QOf-HEltUP"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvallalta/ia3/blob/main/04_Pytorch_con_GPU_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqPW8adYjVJ"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n",
        "\n",
        "#<strong>**Máster en Inteligencia Artificial Avanzada y Aplicada  IA^3**</strong>\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nH891SrsKDo"
      },
      "source": [
        "# Que es CUDA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRsotPs3sKDp"
      },
      "source": [
        "Mucha gente confunde CUDA con un lengaje o con una API. No lo es. Es más que eso. CUDA en una plataforma de cálculo computerizado paralelo y un modelo de programación que permite aprovechar las GPUs para tareas de propósito general de una forma fácil y elegante. Los desarrolladores pueden continuar trabajando en C, C++, Fortran, Python y una lista cada día más amplia e incorpora extensiones de estos lenguajes en forma de unas pocas palabras clave básicas.\n",
        "\n",
        "Estas palabras clave permiten al desarrollador expresar cantidades masivas de paralelismo y dirigir al compilador a la porción de la aplicación que se mapea a la GPU. En definitiva, hace que el acceso a la gran potencia computacional de las GPUs se haya incorporado en los lenguajes de programación de propósito general, permitiendo una gran expansión de técnicas y tecnologías que requieren de esa potencia, como las técnicas de aprensdizaje máquina, inteligencia artificial y más concretamente aprendizaje profundo (_deep learning_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4uAQv4usKDq"
      },
      "source": [
        "# Como instalo PyTorch para GPU?\n",
        "\n",
        "En primer lugar es necesario tener una tarjeta gñrafica NVIDIA compatible y con los drivers CUDA instalado y actualizados correctamente.  A continuación selecciona la versión de Pytorch correspondiente al descargarlo de la [página oficial](https://pytorch.org/get-started/locally/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k_XKh24sKDq"
      },
      "source": [
        "# Como saber si tienes CUDA disponible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N57HhthQsKDr",
        "outputId": "96b98557-442f-4254-dec5-6fba56dbc64d"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "# True"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2a-td3HsKDt"
      },
      "source": [
        "# Usando GPU y CUDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hqUQGbFsKDu",
        "outputId": "e6a9c0d2-5bf8-4489-fe3c-9b6e12bd4c44"
      },
      "source": [
        "## Id del dispositivo por defecto\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wZqoghwjsKDu",
        "outputId": "177bbf1e-3903-4ae7-f3e9-a0c33c58ff3b"
      },
      "source": [
        "# 0\n",
        "torch.cuda.get_device_name(0) # Obtenemos el nombre del dispositivo ID '0'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFS_Uun6sKDv",
        "outputId": "a069c8b0-1282-4332-b827-127bdd1c8fd4"
      },
      "source": [
        "# Retorna el uso de memoria actual provocado por\n",
        "# tensores en bytes para el dispositivo dado\n",
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LegDTTgsKDw",
        "outputId": "a2448a40-1f17-4db4-d475-22da747254ca"
      },
      "source": [
        "# Retorna la memoria gestionada por el Returns the current GPU memory managed by the\n",
        "# gestor de memoria en bytes para el dispositivo dado\n",
        "torch.cuda.memory_cached()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AonHdnetsKDw"
      },
      "source": [
        "# Usando CUDA en lugar de CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGh82BAssKDx"
      },
      "source": [
        "# CPU\n",
        "a = torch.FloatTensor([1.,2.])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe_6Q_MsKDx",
        "outputId": "c6faa250-b262-4179-8703-1ca35858d38a"
      },
      "source": [
        "a"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b-QcGX2sKDy",
        "outputId": "6f39dc44-ade2-406a-ac97-e9818688b615"
      },
      "source": [
        "a.device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRSaR12psKDy"
      },
      "source": [
        "# GPU\n",
        "a = torch.FloatTensor([1., 2.]).cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5UM3xf1sKDz",
        "outputId": "bfe6e33d-5dc9-4fb6-cd45-5fafaefb9cf9"
      },
      "source": [
        "a.device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19pJnecDsKDz",
        "outputId": "681df76b-39bd-4425-baa5-2e47ae154d44"
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlRPFKFKsKD0"
      },
      "source": [
        "## Enviando modelos a la GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYDU7wJlsKD0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VpD2TWB8qH"
      },
      "source": [
        "class Model(nn.Module): \r\n",
        "# Regresion logística\r\n",
        "    def __init__(self, input_size=4, num_classes=3):\r\n",
        "        super().__init__()\r\n",
        "        self.linear = nn.Linear(input_size, num_classes)\r\n",
        "        \r\n",
        "    def forward(self, xb):\r\n",
        "        out = self.linear(xb)\r\n",
        "        return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsYFrEasKD0"
      },
      "source": [
        "class MLP(nn.Module):  #Opcional, solo para probar\n",
        "  # MLP 2 capa oculta\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
        "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
        "        self.out = nn.Linear(h2, out_features)  # output layer\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep0lWyRYsKD1"
      },
      "source": [
        "torch.manual_seed(32)\n",
        "model = Model()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQl9xu5WsKD1",
        "outputId": "ebdb3553-3014-43c4-8520-df72fc1c2c99"
      },
      "source": [
        "# Comprobación: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
        "next(model.parameters()).is_cuda"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atjKSR4ysKD2"
      },
      "source": [
        "gpumodel = model.cuda()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpWkxrvsKD2",
        "outputId": "0798adf4-5035-4bf7-b130-8bac281fe950"
      },
      "source": [
        "next(gpumodel.parameters()).is_cuda"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N0wH5ELaqGr",
        "outputId": "9508f5fb-8bdb-48b2-d3cf-afcdefa73fac"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMLuJp4sKD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "26f0ee9d-673d-46ba-9630-4f27b9ea85b3"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/iris.csv')\n",
        "df.head()\n",
        "#X = df.drop('Species',axis=1).values\n",
        "#y = df['Species'].values\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>,\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\",\"Species\"</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1,5.1,3.5,1.4,0.2,\"setosa\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2,4.9,3,1.4,0.2,\"setosa\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3,4.7,3.2,1.3,0.2,\"setosa\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4,4.6,3.1,1.5,0.2,\"setosa\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5,5,3.6,1.4,0.2,\"setosa\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ,\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\",\"Species\"\n",
              "0                         1,5.1,3.5,1.4,0.2,\"setosa\"                  \n",
              "1                           2,4.9,3,1.4,0.2,\"setosa\"                  \n",
              "2                         3,4.7,3.2,1.3,0.2,\"setosa\"                  \n",
              "3                         4,4.6,3.1,1.5,0.2,\"setosa\"                  \n",
              "4                           5,5,3.6,1.4,0.2,\"setosa\"                  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ncfpk5q_-WP1",
        "outputId": "b6ac206f-f040-4a55-aff8-1c65e654aa74"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2     0.0\n",
              "1                4.9               3.0  ...               0.2     0.0\n",
              "2                4.7               3.2  ...               0.2     0.0\n",
              "3                4.6               3.1  ...               0.2     0.0\n",
              "4                5.0               3.6  ...               0.2     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQYmDDbxCWpU"
      },
      "source": [
        "## Conjuntos Train-Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tSFdICA6KJs"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2G07_ypsKD3"
      },
      "source": [
        "## Convertir Tensores a .cuda() tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTAADv48sKD4"
      },
      "source": [
        "X_train = torch.FloatTensor(X_train).cuda()\n",
        "X_test = torch.FloatTensor(X_test).cuda()\n",
        "y_train = torch.LongTensor(y_train).cuda()\n",
        "y_test = torch.LongTensor(y_test).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgCVuGql_pCD"
      },
      "source": [
        "## Preparacion de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENmTJnbQsKD4"
      },
      "source": [
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXCKApAR_e2I"
      },
      "source": [
        "## Función de coste, optimizador y evaluador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adtAh-XVsKD4"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11hDOTR1fTTZ"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDFh6ggH3s2H"
      },
      "source": [
        "## Entrenamiento con GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2quz2ARSsKD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56530724-c9e3-440b-8246-b82446a3aaf4"
      },
      "source": [
        "import time\n",
        "epochs = 300\n",
        "losses = []\n",
        "accs =[]\n",
        "start = time.time()\n",
        "for i in range(epochs):\n",
        "    i+=1\n",
        "    y_pred = gpumodel.forward(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    acc = accuracy(y_pred, y_train)\n",
        "    losses.append(loss)\n",
        "    accs.append(acc)\n",
        "    \n",
        "    # log:\n",
        "    if i%10 == 1:\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}  acc: {acc.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1  loss: 1.90774024  acc: 0.64999998\n",
            "epoch: 11  loss: 1.05946147  acc: 0.64999998\n",
            "epoch: 21  loss: 0.94435710  acc: 0.35833332\n",
            "epoch: 31  loss: 0.79906476  acc: 0.63333333\n",
            "epoch: 41  loss: 0.72149867  acc: 0.69166666\n",
            "epoch: 51  loss: 0.65472120  acc: 0.93333334\n",
            "epoch: 61  loss: 0.60460609  acc: 0.89166665\n",
            "epoch: 71  loss: 0.56408793  acc: 0.94166666\n",
            "epoch: 81  loss: 0.53180271  acc: 0.94166666\n",
            "epoch: 91  loss: 0.50473028  acc: 0.95833331\n",
            "epoch: 101  loss: 0.48167929  acc: 0.95833331\n",
            "epoch: 111  loss: 0.46155009  acc: 0.95833331\n",
            "epoch: 121  loss: 0.44366735  acc: 0.96666664\n",
            "epoch: 131  loss: 0.42752853  acc: 0.96666664\n",
            "epoch: 141  loss: 0.41278446  acc: 0.96666664\n",
            "epoch: 151  loss: 0.39917985  acc: 0.95833331\n",
            "epoch: 161  loss: 0.38652790  acc: 0.96666664\n",
            "epoch: 171  loss: 0.37468818  acc: 0.96666664\n",
            "epoch: 181  loss: 0.36355385  acc: 0.95833331\n",
            "epoch: 191  loss: 0.35304171  acc: 0.95833331\n",
            "epoch: 201  loss: 0.34308663  acc: 0.95833331\n",
            "epoch: 211  loss: 0.33363569  acc: 0.95833331\n",
            "epoch: 221  loss: 0.32464588  acc: 0.95833331\n",
            "epoch: 231  loss: 0.31608137  acc: 0.95833331\n",
            "epoch: 241  loss: 0.30791172  acc: 0.95833331\n",
            "epoch: 251  loss: 0.30011061  acc: 0.95833331\n",
            "epoch: 261  loss: 0.29265508  acc: 0.96666664\n",
            "epoch: 271  loss: 0.28552455  acc: 0.96666664\n",
            "epoch: 281  loss: 0.27870071  acc: 0.97500002\n",
            "epoch: 291  loss: 0.27216667  acc: 0.96666664\n",
            "TOTAL TRAINING TIME: 0.308866024017334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiywgvRkCyfg",
        "outputId": "2e71d446-2c0f-4238-f703-2fc375c90513"
      },
      "source": [
        "_, preds = torch.max(y_pred, dim=1)\r\n",
        "print(f'Aciertos: {torch.sum(preds == y_train).item()}')\r\n",
        "print(f'Muestras totales: {len(preds)}')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aciertos: 116\n",
            "Muestras totales: 120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laOv0FJc3xJW"
      },
      "source": [
        "# Curiosidad: Volviendo a CPU\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFW2KUGA33Fv",
        "outputId": "f16a7eee-a702-4573-9b0a-21cebe3c73cb"
      },
      "source": [
        "torch.manual_seed(32)\r\n",
        "model2 = Model()\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\r\n",
        "\r\n",
        "X_train = torch.FloatTensor(X_train)\r\n",
        "X_test = torch.FloatTensor(X_test)\r\n",
        "y_train = torch.LongTensor(y_train)\r\n",
        "y_test = torch.LongTensor(y_test)\r\n",
        "\r\n",
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\r\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n",
        "\r\n",
        "import time\r\n",
        "epochs = 300\r\n",
        "losses = []\r\n",
        "start = time.time()\r\n",
        "for i in range(epochs):\r\n",
        "    i+=1\r\n",
        "    y_pred = model2(X_train)\r\n",
        "    loss = criterion(y_pred, y_train)\r\n",
        "    losses.append(loss)\r\n",
        "    \r\n",
        "    # a neat trick to save screen space:\r\n",
        "    if i%10 == 1:\r\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    \r\n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1  loss: 1.90773988\n",
            "epoch: 11  loss: 1.90773988\n",
            "epoch: 21  loss: 1.90773988\n",
            "epoch: 31  loss: 1.90773988\n",
            "epoch: 41  loss: 1.90773988\n",
            "epoch: 51  loss: 1.90773988\n",
            "epoch: 61  loss: 1.90773988\n",
            "epoch: 71  loss: 1.90773988\n",
            "epoch: 81  loss: 1.90773988\n",
            "epoch: 91  loss: 1.90773988\n",
            "epoch: 101  loss: 1.90773988\n",
            "epoch: 111  loss: 1.90773988\n",
            "epoch: 121  loss: 1.90773988\n",
            "epoch: 131  loss: 1.90773988\n",
            "epoch: 141  loss: 1.90773988\n",
            "epoch: 151  loss: 1.90773988\n",
            "epoch: 161  loss: 1.90773988\n",
            "epoch: 171  loss: 1.90773988\n",
            "epoch: 181  loss: 1.90773988\n",
            "epoch: 191  loss: 1.90773988\n",
            "epoch: 201  loss: 1.90773988\n",
            "epoch: 211  loss: 1.90773988\n",
            "epoch: 221  loss: 1.90773988\n",
            "epoch: 231  loss: 1.90773988\n",
            "epoch: 241  loss: 1.90773988\n",
            "epoch: 251  loss: 1.90773988\n",
            "epoch: 261  loss: 1.90773988\n",
            "epoch: 271  loss: 1.90773988\n",
            "epoch: 281  loss: 1.90773988\n",
            "epoch: 291  loss: 1.90773988\n",
            "TOTAL TRAINING TIME: 0.21269488334655762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx_mOPC95Azl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QOf-HEltUP"
      },
      "source": [
        "## Fin del Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDr1zYmBkRV"
      },
      "source": [
        "Referencias y modelos empleados para el Notebook: \r\n",
        "\r\n",
        "*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \r\n",
        "*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\r\n",
        "*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\r\n",
        "*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\r\n",
        "*   Tutoriales y notebooks del curso \"Deep Learning with Pytorch: Zero to GANs\" de [Aakash N S](https://jovian.ai/aakashns)\r\n",
        "* [A visual proof that neural networks can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html), también conocido como Teorema de Aproximación Universal\r\n",
        "* [But what *is* a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) - Una introducción muy intuitiva a lo que son las redes neuronales y lo que implican las capas ocultas."
      ]
    }
  ]
}